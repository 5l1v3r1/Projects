# -*- coding: utf-8 -*-

import glob
import os
import time
from hashlib import md5

import MySQLdb
import numpy as np
from pyAudioAnalysis import audioTrainTest as aT

from config import *  # Set mysql parameter is a file called config.py: host=, user=, passwd=, database=


def do_division(a, b):
    if a == 0 and b == 0:
        return 0.0
    else:
        return float(a) / float(b)

def unshared_copy(inList):
    #https://stackoverflow.com/questions/1601269/how-to-make-a-completely-unshared-copy-of-a-complicated-list-deep-copy-is-not
    if isinstance(inList, list):
        return list( map(unshared_copy, inList) )
    return inList


def test_model(test_dirs, model_dir=os.getcwd(), modelName='Test', classifierType='svm', level=0.7,
               store_to_mySQL=False, verbose=False):
    # Used to test an existing model against new samples;
    # Test directories should contain the same categories and be in the same order as the original training data, but should contain seperate samples
    # model_dir is the path to the model file generated by the training function
    # modelName is the name of the model file generated by the trainging function
    # classifierType is the ML method used and should be the same as the training method used. Should be one of: svm, knn, gradientboosting, randomforest, extratrees
    # certainty_threshold: Any results with confidence below this should be treated as indeterminate
    # Level is confidence threshold above which test results should be considered
    # When store_to_mySQL is set to True results will be pushed to mySQL table specified in config.py

    # The following sets up a new table in the given db to store information about each classification; The table will be given the same name as the model file; the table will be dropped initially if a table with the same name already exists.

    start_time = time.clock()

    table_setup = '(filename VARCHAR(512), class VARCHAR(512), identifiedCorrectly VARCHAR(512), confidence DOUBLE, PRIMARY KEY (filename));'

    if store_to_mySQL:
        with MySQLdb.connect(host=host, user=user, passwd=passwd,
                             db=database) as cur:  # config is in config.py: see above

            try:
                cur.execute("DROP TABLE " + modelName)
            except:
                pass

            cur.execute("CREATE TABLE " + modelName + table_setup)

    os.chdir(test_dirs[0])
    for file in glob.glob(u"*.wav"):  # Iterate through each wave file in the directory
        Result, P, classNames = aT.fileClassification(file, os.path.join(model_dir, modelName),
                                                      classifierType)  # Test the file
        break

    if classNames == -1:
        raise Exception("Model file " + os.path.join(model_dir, modelName) + " not found!")

    num_cats = len(classNames)
    temp = []
    for j in xrange(0, num_cats):
        temp.append(0)
    confusion_matrix = []
    for k in xrange(0, num_cats):
        confusion_matrix.append(unshared_copy(temp))

    confidence_above_90 = unshared_copy(temp)
    correct_above_90 = unshared_copy(temp)
    total_num_samples = unshared_copy(temp)
    confidence_corrected_con_matrix = unshared_copy(confusion_matrix)
    for i in xrange(0, len(test_dirs)):  # Iterate through each test directory
        dir = test_dirs[i]
        os.chdir(dir)
        rootdir, correct_cat = os.path.split(dir)
        for file in glob.glob(u"*.wav"):  # Iterate through each wave file in the directory
            Result, P, classNames = aT.fileClassification(file, os.path.join(model_dir, modelName),
                                                          classifierType)  # Test the file

            if verbose:
                print '\n', file
                print Result
                print classNames
                print P, '\n'

            if store_to_mySQL:
                current_file_results = {
                    'filename': unicode(md5(file.encode('utf-8')).hexdigest()),
                    'class': correct_cat,
                    'identifiedCorrectly': str(unicode(correct_cat) == unicode(classNames[int(Result)])).upper(),
                    'confidence': str(max(P))
                }
                with MySQLdb.connect(host=host, user=user, passwd=passwd, db=database) as cur:
                    insert_statement = "INSERT INTO " + modelName + " (filename, class, identifiedCorrectly, confidence) VALUES (\'" + \
                                       current_file_results['filename'] + "\', \'" + current_file_results[
                                           'class'] + '\', ' + current_file_results['identifiedCorrectly'] + ', ' + \
                                       current_file_results['confidence'] + ");"
                    try:
                        cur.execute(insert_statement)
                    except:
                        pass

            indexes = [t for t, x in enumerate(classNames) if unicode(x) == unicode(correct_cat)]
            if not len(indexes):
                raise Exception(correct_cat + "is not a correctly named category for this model!")
            elif len(indexes) != 1:
                raise Exception(correct_cat + "matches multiple categories in the model file!")
            cat_index = indexes[0]
            total_num_samples[cat_index] += 1
            confusion_matrix[cat_index][int(Result)] += 1
            if max(P) > level:
                confidence_corrected_con_matrix[cat_index][int(Result)] += 1
                confidence_above_90[cat_index] += 1
                if unicode(correct_cat) == unicode(classNames[int(Result)]):
                    correct_above_90[cat_index] += 1

    acc_above_90 = map(do_division, correct_above_90, confidence_above_90)
    percent_desicive_samples = map(do_division, confidence_above_90, total_num_samples)

    print '\n', "Agregated Results: ", '\n'
    print classNames
    print "acc above ", level, ": ", acc_above_90
    print "percent samples above ", level, ": ", percent_desicive_samples
    print "total samples tested in each category: ", total_num_samples, '\n'
    print "confusion matrix:"
    aT.printConfusionMatrix(np.array(confusion_matrix), classNames)
    print "\n", "confidence adjusted confustion matrix:"
    aT.printConfusionMatrix(np.array(confidence_corrected_con_matrix), classNames)

    print '\n', "Processed ", sum(total_num_samples), " samples in ", time.clock() - start_time, " seconds."
